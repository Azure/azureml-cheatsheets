(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{117:function(e,n,t){"use strict";t.d(n,"a",(function(){return d}));var r=t(0),a=t.n(r);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function c(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function u(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var p=a.a.createContext({}),s=function(e){var n=a.a.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):c(c({},n),e)),t},l={inlineCode:"code",wrapper:function(e){var n=e.children;return a.a.createElement(a.a.Fragment,{},n)}},m=a.a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,o=e.parentName,p=u(e,["components","mdxType","originalType","parentName"]),m=s(t),d=r,g=m["".concat(o,".").concat(d)]||m[d]||l[d]||i;return t?a.a.createElement(g,c(c({ref:n},p),{},{components:t})):a.a.createElement(g,c({ref:n},p))}));function d(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,o=new Array(i);o[0]=m;var c={};for(var u in n)hasOwnProperty.call(n,u)&&(c[u]=n[u]);c.originalType=e,c.mdxType="string"==typeof e?e:r,o[1]=c;for(var p=2;p<i;p++)o[p]=t[p];return a.a.createElement.apply(null,o)}return a.a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},139:function(e,n,t){"use strict";t.r(n),n.default=t.p+"assets/images/run-ex-sine-a78600f095ae349a514b9d3e3e3dbcea.png"},80:function(e,n,t){"use strict";t.r(n),t.d(n,"frontMatter",(function(){return o})),t.d(n,"metadata",(function(){return c})),t.d(n,"toc",(function(){return u})),t.d(n,"default",(function(){return s}));var r=t(3),a=t(7),i=(t(0),t(117)),o={title:"Experiment and Run",description:"Guide to running code with Azure ML",keywords:["run","experiment","submit","remote","ScriptRunConfig"]},c={unversionedId:"cheatsheets/python/v1/run",id:"cheatsheets/python/v1/run",isDocsHomePage:!1,title:"Experiment and Run",description:"Guide to running code with Azure ML",source:"@site/docs/cheatsheets/python/v1/run.md",sourceDirName:"cheatsheets/python/v1",slug:"/cheatsheets/python/v1/run",permalink:"/azureml-cheatsheets/ja/docs/cheatsheets/python/v1/run",editUrl:"https://github.com/Azure/azureml-cheatsheets/tree/main/website/docs/cheatsheets/python/v1/run.md",version:"current",frontMatter:{title:"Experiment and Run",description:"Guide to running code with Azure ML",keywords:["run","experiment","submit","remote","ScriptRunConfig"]}},u=[{value:"Concepts",id:"concepts",children:[{value:"Run",id:"run",children:[]},{value:"Experiments",id:"experiments",children:[]}]},{value:"Create Run",id:"create-run",children:[{value:"Via ScriptRunConfig",id:"via-scriptrunconfig",children:[]},{value:"Get Context",id:"get-context",children:[]},{value:"Interactive",id:"interactive",children:[]}]}],p={toc:u};function s(e){var n=e.components,o=Object(a.a)(e,["components"]);return Object(i.a)("wrapper",Object(r.a)({},p,o,{components:n,mdxType:"MDXLayout"}),Object(i.a)("h2",{id:"concepts"},"Concepts"),Object(i.a)("h3",{id:"run"},"Run"),Object(i.a)("p",null,"A run represents a single execution of your code."),Object(i.a)("p",null,"Azure ML is a machine-learning service that facilitates running your code in\nthe cloud. A ",Object(i.a)("inlineCode",{parentName:"p"},"Run")," is an abstraction layer around each such submission, and is used to\nmonitor the job in real time as well as keep a history of your results."),Object(i.a)("h3",{id:"experiments"},"Experiments"),Object(i.a)("p",null,"An experiment is a light-weight container for ",Object(i.a)("inlineCode",{parentName:"p"},"Run"),". Use experiments to submit\nand track runs."),Object(i.a)("p",null,"Create an experiment in your workspace ",Object(i.a)("inlineCode",{parentName:"p"},"ws"),"."),Object(i.a)("pre",null,Object(i.a)("code",{parentName:"pre",className:"language-python"},"from azureml.core import Experiment\nexp = Experiment(ws, '<experiment-name>')\n")),Object(i.a)("h2",{id:"create-run"},"Create Run"),Object(i.a)("h3",{id:"via-scriptrunconfig"},"Via ScriptRunConfig"),Object(i.a)("p",null,"Usually a run is created by submitting a ScriptRunConfig."),Object(i.a)("pre",null,Object(i.a)("code",{parentName:"pre",className:"language-python"},"from azureml.core import Workspace, Experiment, ScriptRunConfig\nws = Workspace.from_config()\nexp = Experiment(ws, '<experiment-name>')\n\nconfig = ScriptRunConfig(source_directory=<'<path/to/script>'>, script='train.py', ...)\nrun = exp.submit(config)\n")),Object(i.a)("p",null,"For more details: ",Object(i.a)("a",{parentName:"p",href:"script-run-config"},"ScriptRunConfig")),Object(i.a)("h3",{id:"get-context"},"Get Context"),Object(i.a)("p",null,"Code that is running within Azure ML is associated to a ",Object(i.a)("inlineCode",{parentName:"p"},"Run"),". The submitted code\ncan access its own run."),Object(i.a)("pre",null,Object(i.a)("code",{parentName:"pre",className:"language-py"},"from azureml.core import Run\nrun = Run.get_context()\n")),Object(i.a)("h4",{id:"example-logging-metrics-to-current-run-context"},"Example: Logging metrics to current run context"),Object(i.a)("p",null,"A common use-case is logging metrics in a training script."),Object(i.a)("pre",null,Object(i.a)("code",{parentName:"pre",className:"language-py",metastring:'title="train.py"',title:'"train.py"'},"from azureml.core import Run\n\nrun = Run.get_context()\n\n# training code\nfor epoch in range(n_epochs):\n    model.train()\n    ...\n    val = model.evaluate()\n    run.log('validation', val)\n")),Object(i.a)("p",null,"When this code is submitted to Azure ML (e.g. via ScriptRunConfig) it will log metrics to its assocaited run."),Object(i.a)("p",null,"For more details: ",Object(i.a)("a",{parentName:"p",href:"logging"},"Logging Metrics")),Object(i.a)("h3",{id:"interactive"},"Interactive"),Object(i.a)("p",null,"In an interactive setting e.g. a Jupyter notebook"),Object(i.a)("pre",null,Object(i.a)("code",{parentName:"pre",className:"language-python"},"run = exp.start_logging()\n")),Object(i.a)("h4",{id:"example-jupyter-notebook"},"Example: Jupyter notebook"),Object(i.a)("p",null,"A common use case for interacive logging is to train a model in a notebook."),Object(i.a)("pre",null,Object(i.a)("code",{parentName:"pre",className:"language-py"},"from azureml.core import Workspace\nfrom azureml.core import Experiment\nws = Workspace.from_config()\nexp = Experiment(ws, 'example')\n\nrun = exp.start_logging()                   # start interactive run\nprint(run.get_portal_url())                 # get link to studio\n\n# toy example in place of e.g. model\n# training or exploratory data analysis\nimport numpy as np\nfor x in np.linspace(0, 10):\n    y = np.sin(x)\n    run.log_row('sine', x=x, y=y)           # log metrics\n\nrun.complete()                              # stop interactive run\n")),Object(i.a)("p",null,"Follow the link to the run to see the metric logging in real time."),Object(i.a)("p",null,Object(i.a)("img",{src:t(139).default})))}s.isMDXComponent=!0}}]);